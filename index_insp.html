<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aniruddha Mahapatra</title>
  
  <meta name="author" content="Anirudh S Chakravarthy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/avatar-modified.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  </tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aniruddha Mahapatra</name>
              </p>
              <p>
                I am a Research Engineer at <a href="https://research.adobe.com/">Adobe Research</a>. I completed my <a href="https://ri.cmu.edu/education/academic-programs/master-of-science-computer-vision">Masters in Computer Vision</a> (MSCV)
                from <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a>, where I was advised by Prof. <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>.
                My research interest include image and video synthesis and editing using generative models.
                <br>
                <br>
                I am fortunate to have worked with <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>, <a href="http://hsinyinglee.com/">Hsin-Ying Lee</a>
                and <a href="http://www.stulyakov.com/">Sergey Tulyakov</a> at Snap Research, <a href="https://kuldeepkulkarni.github.io/">Kuldeep Kulkarni</a>, 
                <a href="https://research.adobe.com/person/anandhavelu-n/">Anandhavelu Natarajan</a> and 
                <a href="https://research.adobe.com/person/subrata-mitra/">Subrata Mitra</a> at 
                Adobe Research, <a href="https://www.linkedin.com/in/jitendra-singh-41a87515/?originalSubdomain=in">Jitendra Singh</a>
                at IBM Research, and, Professor <a href="https://biplab-banerjee.github.io/">Biplab Banerjee</a> and <a href="https://www.researchgate.net/profile/Ranita-Biswas">Ranita Biswas</a> at 
                Indian Institute of Technology, Roorkee.
        
                <br>
                <br>
        
                <!-- I will be attending <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a>  thx -->
        
                </p>
              
              <p style="text-align:center">
                <a href="mailto:aniruddha26398@gmail.com">Email</a> &nbsp|&nbsp
                <a href="./data/resume.pdf">Resume</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?user=p8Hdn7gAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/aniruddha98/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/avatar-modified.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar-modified.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
          <tr>
              <!-- <th width="16.7%" valign="top" align="center">
              <img src="images/snap_logo.png" alt="sym" width="60%"></a>
              <p style="line-height:1.3; font-size:12pt">Snap Inc.<br>Research Intern<br>May. 21 - Aug. 21</p>
              </th> -->

              <td width="13.8%" valign="top" align="center">
                <img src="images/adobe.jpeg" alt="sym" width="110%"></a>
                <p style="line-height:1.3;"><a href="https://research.adobe.com/">Adobe Research</a><br>Research Engineer<br>Feb. 24 - Present</p>
                </td>
      
              <td width="13.8%" valign="top" align="center">
              <img src="images/cmu.png" alt="sym" width="90%"></a>
              <!-- <p style="line-height:1.3; font-size:12pt">CMU<br>M.S. in Computer Vision<br>Jan. 21 - June. 22</p> -->
              <p style="line-height:1.3;"><a href="https://www.cs.cmu.edu/">CMU</a><br>MS in Computer Vision<br>Aug. 22 - Dec. 23</p>
              </td>

              <td width="13.8%" valign="top" align="center">
              <img src="images/snap_logo.png" alt="sym" width="57%"></a>
              <!-- <p style="line-height:1.3; font-size:12pt">CMU<br>M.S. in Computer Vision<br>Jan. 21 - June. 22</p> -->
              <p style="line-height:1.3;"><a href="https://www.cs.cmu.edu/">Snap Research</a><br>Research Intern<br>May. 23 - Aug. 23</p>
              </td>
      
              <td width="13.8%" valign="top" align="center">
              <img src="images/adobe.jpeg" alt="sym" width="110%"></a>
              <p style="line-height:1.3;"><a href="https://research.adobe.com/">Adobe Research</a><br>Research Associate<br>Aug. 20 - Aug. 22</p>
              </td>
      
              <td width="13.8%" valign="top" align="center">
              <img src="images/adobe.jpeg" alt="sym" width="110%"></a>
              <p style="line-height:1.3;"><a href="https://research.adobe.com/">Adobe Research</a><br>Research Intern<br>May. 19 - Jul. 19</p>
              </td>
      
              <!-- <td width="13.8%" valign="top" align="center">
              <img src="images/ibm.svg" alt="sym" width="60%"></a>
              <p style="line-height:1.3;"><a href="https://www.ibm.com/in-en">IBM</a><br>Remote Research Intern<br>Jun. 18 - Dec. 18</p>
              </td> -->
      
              <!-- <th width="16.6%" valign="top" align="center">
              <img src="images/relajet.png" alt="sym" width="60%"></a>
              <p style="line-height:1.3; font-size:12pt">RelaJet<br>Intern<br>March 18 - Aug. 18</p>
              </th> -->
      
              <td width="16.6%" valign="top" align="center">
              <img src="images/iitr.jpeg" alt="sym" width="50%"></a>
              <p style="line-height:1.3;"><a href="https://iitr.ac.in/">IIT Roorkee</a><br>
                B.Tech. Computer Science<br>
                Jul. 16 - Jul. 20</p>
              </td>
          </tr>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Software</heading>
          <!-- <p>
            My current research at CMU and Argo AI is focused on discovering novel objects in an open-world setting. 
          </p> -->
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ddp_image'>
            <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 15px;">
              <source src="./images/moving_elements.mp4" type="video/mp4">
            </video>
            </div>
            <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 15px;">
              <source src="./images/moving_elements.mp4" type="video/mp4">
            </video>
        </div>
        <script type="text/javascript">
          function ddp_start() {
            document.getElementById('ddp_image').style.opacity = "1";
          }
  
          function ddp_stop() {
            document.getElementById('ddp_image').style.opacity = "0";
          }
          ddp_stop()
        </script>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <a href="https://helpx.adobe.com/photoshop-elements/using/moving-elements.html">
          <papertitle>Moving Elements</papertitle>
        </a>
        <br>
        <a href="https://www.youtube.com/watch?v=W-9D_-ilS1Y">video</a> |
        <a href="https://helpx.adobe.com/photoshop-elements/using/moving-elements.html">website</a>
        
        <p></p>
        <p>
          Adobe's Photoshop Elements 2023 new feature "Moving Elements" lets users generate aesthetic cinemagraphs from their photos.
          <br>
          This feature was based on our <a href="https://controllable-cinemagraphs.github.io/">Controllable Animation of Fluid Elements in Still Images</a> (CVPR 2022) work.
      </p>
    </td>
  </tr>

    </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p>
                My current research at CMU and Argo AI is focused on discovering novel objects in an open-world setting. 
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 25px;">
                    <source src="./images/co-speech-cropped.mp4" type="video/mp4">
                  </video>
                  </div>
                  <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 25px;">
                    <source src="./images/co-speech-cropped.mp4" type="video/mp4">
                  </video>
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://cospeech-gesture-3d.github.io/website/index.html">
                <papertitle>Co-speech Gesture Video Generation with 3D Human Meshes</papertitle>
              </a>
              <br>
              <strong>Aniruddha Mahapatra*</strong>,
              <a href="">Richa Mishra*</a>, 
              <a href="">Renda Li</a>, 
              <a href="">Ziyi Chen</a>,
              <a href="">Boyang Ding</a>,
              <a href="">Shoulei Wang</a>,
              <a href="">Jun-Yan Zhu</a>,
              <a href="">Peng Chang</a>,
              <a href="">Mei Han</a>,
              <a href="">Jing Xiao</a>
              <br>
              <em>ECCV</em>, 2024
              <br>
              <a href="https://cospeech-gesture-3d.github.io/website/index.html">webpage</a> |
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/12483.pdf">paper</a> |
              <a href="data/cospeech.txt">bibTeX</a>
              
              <p></p>
              <p>
              Existing hand gesture video generation methods are primarily limited by the widely adopted 2D skeleton-based gesture representation and still struggle to generate realistic hands.
              We introduce a co-speech video generation framework to synthesize human speech videos leveraging human mesh-based representations. 
            </p>
          </td>
        </tr>

          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 0px;">
                    <source src="./images/content-debiased-fvd.mp4" type="video/mp4">
                  </video>
                  </div>
                  <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: 0px;">
                    <source src="./images/content-debiased-fvd.mp4" type="video/mp4">
                  </video>
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://content-debiased-fvd.github.io/">
                <papertitle>On the Content Bias in Fréchet Video Distance</papertitle>
              </a>
              <br>
              <a href="https://songweige.github.io/">Songwei Ge</a>, 
              <strong>Aniruddha Mahapatra</strong>,
              <a href="https://gauravparmar.com/">Gaurav Parmar</a>, 
              <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>,
              <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://content-debiased-fvd.github.io/">webpage</a> |
              <a href="https://arxiv.org/pdf/2404.12391">paper</a> |
              <a href="https://arxiv.org/abs/2404.12391">arXiv</a> |
              <a href="https://github.com/songweige/content-debiased-fvd">code</a> |
              <a href="data/cfvd.txt">bibTeX</a>
              
              <p></p>
              <p>
                We analyse the problems associated with the commonly used I3D features for computing FVD metric that is used to evaluate quality of generated videos.
                We develop code and provide pre-computed features for computing FVD with different feature extractors. The toolkit is available at <a href="https://content-debiased-fvd.github.io/documentation/">Github repo</a>. 
                <br>
                <br>
                <code>pip install cd-fvd</code>
            </p>
          </td>
        </tr>
          
          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: -25px;">
                  <source src="./images/video.mp4" type="video/mp4">
                </video>
                </div>
                <video autoplay loop muted playsinline width="200" style="border-radius:0px; border: 1px solid #000; margin-top: -25px;">
                  <source src="./images/video.mp4" type="video/mp4">
                </video>
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://text2cinemagraph.github.io/website/">
              <papertitle>Text-Guided Synthesis of Eulerian Cinemagraphs</papertitle>
            </a>
            <br>
            <strong>Aniruddha Mahapatra</strong>,
            <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>, 
            <a href="http://hsinyinglee.com/">Hsin-Ying Lee</a>, <br>
            <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>, 
            <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>
            <br>
            <em>SIGGRAPH Asia</em>, 2023 <b>(ACM Transactions on Graphics)</b>
            <br>
            <a href="https://text2cinemagraph.github.io/website/">webpage</a> |
            <a href="https://arxiv.org/pdf/2307.03190.pdf">paper</a> |
            <a href="https://arxiv.org/abs/2307.03190">arXiv</a> |
            <a href="https://github.com/text2cinemagraph/text2cinemagraph">code</a> |
            <a href="data/text2cinemagraph.txt">bibTeX</a>
            
            <p></p>
            <p>
              We introduce a fully automated method, Text2Cinemagraph, for creating cinemagraphs from text descriptions - 
              an especially challenging task when prompts feature imaginary elements and artistic styles, 
              given the complexity of interpreting the semantics and motions of these images. Our method also gives the user a coarse control over the direction of motion in the generated cinemagraphs using text-based direction.
          </p>
        </td>
      </tr>

          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <video autoplay loop muted playsinline width="200" style="border-radius:0px;border: 1px solid #000;margin-top: -5px;">
                  <source src="./images/MovingElements_1.mp4" type="video/mp4">
                </video>
                </div>
                <video autoplay loop muted playsinline width="200" style="border-radius:0px;border: 1px solid #000;margin-top: -5px;">
                  <source src="./images/MovingElements_1.mp4" type="video/mp4">
                </video>
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://controllable-cinemagraphs.github.io/">
              <papertitle>Controllable Animation of Fluid Elements in Still Images</papertitle>
            </a>
            <br>
            <strong>Aniruddha Mahapatra</strong>,
            <a href="https://kuldeepkulkarni.github.io/">Kuldeep Kulkarni</a>
            <br>
            <em>CVPR</em>, 2022
            <br>
            <a href="https://controllable-cinemagraphs.github.io/">webpage</a> |
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.pdf">paper</a> |
            <a href="https://arxiv.org/abs/2112.03051">arXiv</a> |
            <a href="https://www.youtube.com/watch?v=uN1uNWQOdb0&t=1s">video</a> |
            <a href="data/moving-elements.txt">bibTeX</a>
            
            <p></p>
            <p>
              Given a single input image, mask the region user wants to animate 
              and any number of arrow directions and their associated speeds provided by the user to specify the direction of desired movement, we 
              propose a method to interactively control the animation of fluid 
              elements (like water, fire, clouds, etc.) to generate cinemagraphs from the single image.  
          </p>
        </td>
      </tr>
          
          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <img src='images/gems-square.png' style="margin-top: -25px;border: 1px solid #000;" width="200"></div>
                <img src='images/gems-square.png' style="margin-top: -25px;border: 1px solid #000;" width="200">
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_GEMS_Scene_Expansion_Using_Generative_Models_of_Graphs_WACV_2023_paper.pdf">
                <papertitle>GEMS: Scene Expansion using Generative Models of Graphs</papertitle>
              </a>
              <br>
              <strong>Aniruddha Mahapatra*</strong>,
              <a href="https://www.cse.iitb.ac.in/~rishiagarwal/">Rishi Agarwal*</a>,
              <a href="https://www.linkedin.com/in/tirupati-saketh-chandra-9b5b17163/?originalSubdomain=in">Tirupati Saketh Chandra*</a>, 
              <a href="https://vaidehi99.github.io/">Vaidehi Patil*</a>, 
              <a href="https://kuldeepkulkarni.github.io/">Kuldeep Kulkarni</a>,
              <a href="https://www.linkedin.com/in/vishwa-vinay-b1b6881?original_referer=https%3A%2F%2Fyou%2Ecom%2F&originalSubdomain=in">Vishwa Vinay</a>
              <br>
              <em>WACV</em>, 2023
              <br>
              <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_GEMS_Scene_Expansion_Using_Generative_Models_of_Graphs_WACV_2023_paper.pdf">paper</a> |
              <a href="https://arxiv.org/abs/2207.03729">arXiv</a> |
              <a href="data/gems.txt">bibTeX</a>
              
              <p></p>
              <p>
                We design an auto-regressive model, GEMS, for a novel task of conditional expansion
                of scene graphs from a given seed scene graph that adds nodes and edges hierarchically to the seed scene graph. 
                We also propose novel metrics to evaluate the quality of expanded scene graphs to capture
                the coherence of predicted edges and nodes better than traditional MMD based metrics.
            </p>
          </td>
        </tr>


        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/emnlp-2022.png' width="200" style="margin-top: 10px;border: 1px solid #000;" width="200"></div>
              <img src='images/emnlp-2022.png' width="200" style="margin-top: 10px;border: 1px solid #000;" width="200">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://aclanthology.org/2022.emnlp-main.61.pdf">
              <papertitle>Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models</papertitle>
            </a>
            <br>
            <strong>Aniruddha Mahapatra</strong>,
            <a href="https://www.linkedin.com/in/sharmila-reddy-nangi/">Snarmila Nangi</a>,
            <a href="https://research.adobe.com/person/aparna-garimella/">Aparna Garimella</a>,
            <a href="https://research.adobe.com/person/anandhavelu-n/">Anandhavelu Natarajan</a>
            <br>
            <em>EMNLP</em>, 2022 <b><font color="red">(Oral)</font></b>
            <br>
            <a href="https://aclanthology.org/2022.emnlp-main.61.pdf">paper</a> |
            <a href="data/uda.txt">bibTeX</a
            
            <p></p>
            <p>
              We introduce effective ways of dataset selection for pretraining large language models in an unsupervised way to facilitate domian adaptation to very limited data domains.
          </p>
            
        </td>
      </tr>

        

      <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
        <td style="padding:20px;width:30%;vertical-align:middle">
          <div class="one">
            <div class="two" id='ddp_image'>
              <img src='images/semie-square.png' width="200" style="margin-top: -20px;border: 1px solid #000;" width="200"></div>
            <img src='images/semie-square.png' width="200" style="margin-top: -20px;border: 1px solid #000;" width="200">
          </div>
          <script type="text/javascript">
            function ddp_start() {
              document.getElementById('ddp_image').style.opacity = "1";
            }
    
            function ddp_stop() {
              document.getElementById('ddp_image').style.opacity = "0";
            }
            ddp_stop()
          </script>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://semie-iccv.github.io/">
            <papertitle>SemIE: Semantically-aware Image Extrapolation</papertitle>
          </a>
          <br>
          <a href="https://www.linkedin.com/in/bholeshwar-khurana/">Bholeshwar Khurana</a>, 
          <a href="https://www.linkedin.com/in/soumya-ranjan-dash-2b651b172/?original_referer=https%3A%2F%2Fyou%2Ecom%2F&originalSubdomain=in">Soumya Ranjan Dash</a>, 
          <a href="https://www.linkedin.com/in/abhishek-bhatia-177248195/?originalSubdomain=in">Abhishek Bhatia</a>,
          <strong>Aniruddha Mahapatra</strong>,
          <a href="https://singh-hrituraj.github.io/">Hrituraj Singh</a>,
          <a href="https://kuldeepkulkarni.github.io/">Kuldeep Kulkarni</a>
          <br>
          <em>ICCV</em>, 2021
          <br>
          <a href="https://semie-iccv.github.io/">webpage </a> |
        <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Khurana_SemIE_Semantically-Aware_Image_Extrapolation_ICCV_2021_paper.pdf">paper</a> |
        <a href="https://arxiv.org/abs/2108.13702">arXiv</a> |
        <a href="data/semie.txt">bibTeX</a> |
        <a href="https://drive.google.com/file/d/1ifo5VApx8tEBhVF1a9LPYx1Ackz-btHv/view">video (infinite zooming-out)</a>
          
          <p></p>
          <p>
            We propose a semantically-aware novel paradigm to perform image extrapolation 
            that enables the addition of new object instances.
        </p>
          
      </td>
    </tr>

        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/uda3.png' width="200" style="margin-top: 20px;border: 1px solid #000;" width="200"></div>
              <img src='images/uda3.png' width="200" style="margin-top: 20px;border: 1px solid #000;" width="200">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="data/paper_uda.pdf">
              <papertitle>Unsupervised Domain Adaptation for Remote Sensing Images Using Metric Learning and Correlation Alignment</papertitle>
            </a>
            <br>
            <strong>Aniruddha Mahapatra</strong>,
            <a href="https://biplab-banerjee.github.io/">Biplab Banerjee</a>
            <br>
            <em>NCVPRIPG 2019</em>, 2021 <b><font color="red">(Oral)</font></b>
            <br>
            <a href="data/paper_uda.pdf">paper</a> |
            <a href="data/uda.txt">bibTeX</a
            
            <p></p>
            <p>
              We prose an end-to-end trainable neural network-based unsupervised 
              DA module for RS image classification that learns a shared embedding 
              space for both the domains which are also deemed to be discriminative 
              by jointly optimizing the contrastive loss and minimizing the difference 
              of the two domain higher-order statistics.
          </p>
            
        </td>
      </tr>

          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <img src='images/sentinal-square2.png' width="200" style="margin-top: -10px;border: 1px solid #000;" width="200"></div>
                <img src='images/sentinal-square2.png' width="200" style="margin-top: -10px;border: 1px solid #000;" width="200">
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8900491">
                <papertitle>Assessment of Sentinel-1 and Sentinel-2 Satellite Imagery for Crop Classification in Indian Region During Kharif and Rabi Crop Cycles</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/bholeshwar-khurana/">Jitendra Singh</a>, 
              <strong>Aniruddha Mahapatra</strong>,
              <a href="https://scholar.google.com/citations?user=wEx_7AkAAAAJ&hl=en">Saurav Basu</a>,
              <a href="https://biplab-banerjee.github.io/">Biplab Banerjee</a>
              <br>
              <em>IEEE IGARSS</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8900491">paper</a> |
              <a href="data/sentinal.txt">bibTeX</a>
              
              <p></p>
              <p>
                We evaluate the potential of Sentinel-1 Synthetic Aperture Radar (SAR) 
                and Sentinel-2 optical imagery in crop classification for an Indian 
                region using multi-class classification algorithm based on the support 
                vector machine (SVM) by applying it to the temporal features extracted 
                from the two imagery data.
            </p>
              
          </td>
        </tr>



        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
            <!-- </td> -->
          <!-- </tr>
          <tr> -->
          <ul>
            <br>
            <!-- <br> -->
            <li> <strong>[Feb/2024]</strong> Joined <a href="https://research.adobe.com/">Adobe Research</a>, San Jose as Research Engineer!</li>
            <li> <strong>[Dec/2023]</strong> Completed <a href="https://ri.cmu.edu/education/academic-programs/master-of-science-computer-vision">Masters in Computer Vision</a> (MSCV) program at <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a> (CMU)!</li>
            <li> <strong>[Jul/2023]</strong> Paper <a href="https://text2cinemagraph.github.io/website/">"Text-Guided Synthesis of Eulerian Cinemagraphs”</a> accepted at <a href="https://asia.siggraph.org/2023/">SIGGRAPH Asia 2023</a> <b>(TOG)</b>!</li>
            <li> <strong>[May/2023]</strong> Started Research Internship at <a href="https://research.snap.com/">Snap Research</a></li>
            <li> <strong>[Oct/2022]</strong> Paper <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_GEMS_Scene_Expansion_Using_Generative_Models_of_Graphs_WACV_2023_paper.pdf">“GEMS: Scene Expansion using Generative
              Models of Graphs”</a> accepted at <a href="https://wacv2023.thecvf.com/">WACV 2023</a>!</li>
            <li> <strong>[Oct/2022]</strong> Paper <a href="https://aclanthology.org/2022.emnlp-main.61.pdf">“Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models”</a> accepted at <a href="https://2022.emnlp.org/">EMNLP 2022</a> <b>(Oral)</b>!</li>
            <li> <strong>[Sept/2022]</strong> Joined Generative Intelligence Lab (<a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu's</a>) group at CMU as Research Assistant. </li>
            <li> <strong>[Aug/2022]</strong> Started my <a href="https://ri.cmu.edu/education/academic-programs/master-of-science-computer-vision">Masters in Computer Vision</a> (MSCV)
              program at <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a> (CMU).</li>
            <!-- <li> <strong>[Jul/2022]</strong> New paper <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_GEMS_Scene_Expansion_Using_Generative_Models_of_Graphs_WACV_2023_paper.pdf">“GEMS: Scene Expansion using Generative
              Models of Graphs”</a> uploaded on ArXiv.</li> -->
            <li> <strong>[Mar/2022]</strong> Paper <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.pdf">“Controllable Animation of Fluid Elements in Still Images”</a> accepted at <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>!</li>
            <!-- <li> <strong>[Feb/2022]</strong> Received admit for Masters in Computer Vision at <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a>!</li> -->
            <li> <strong>[Feb/2022]</strong> Promoted to Research Associate 2 at <a href="https://research.adobe.com/">Adobe Research</a>, India!</li>
            <li> <strong>[Jun/2021]</strong> Paper <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Khurana_SemIE_Semantically-Aware_Image_Extrapolation_ICCV_2021_paper.pdf">“SemIE: Semantically-aware Image Extrapolation”</a> accepted at <a href="https://iccv2021.thecvf.com/">ICCV 2021</a>!</li>
            <li> <strong>[Aug/2020]</strong> Joined <a href="https://research.adobe.com/">Adobe Research</a>, India as Research Associate!</li>
            <li> <strong>[Jul/2020]</strong> Completed Bachelors in Computer Scinece from <a href="https://iitr.ac.in/">IIT Roorkee</a>.</li>
            <li> <strong>[Oct/2019]</strong> Paper <a href="data/paper_uda.pdf">“Unsupervised Domain Adaptation for Remote Sensing Images Using Metric Learning and Correlation Alignment”</a> accepted <b>(Oral)</b> at <a href="http://ncvpripg.kletech.ac.in/">NCVPRIPG 2019</a>!</li>
            <!-- <li> <strong>[Sep/2019]</strong> Received Research Associate offer from <a href="https://research.adobe.com/">Adobe Research</a>, India.</li> -->
            <li> <strong>[May/2019]</strong> Started Research Internship at <a href="https://research.adobe.com/">Adobe Research</a>, India.</li>
            <li> <strong>[Apr/2019]</strong> Paper <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8900491">“Assessment of Sentinel-1 and Sentinel-2 Satellite Imagery for Crop Classification in Indian Region During Kharif and Rabi Crop Cycles”</a> accepted at <a href="https://www.igarss2019.org/">IGARSS 2019</a>!</li>
            <!-- <li> <strong>[Aug/2018]</strong> Accepted for Research Internship at <a href="https://research.adobe.com/">Adobe Research</a>, India for summer 2019!</li>
            <li> <strong>[Jun/2018]</strong> Excited to work with <a href="https://biplab-banerjee.github.io/">Prof. Biplab Banerjee</a> and <a href="https://www.ibm.com/in-en">IBM Research</a>, India over the semester.</li> -->
          </ul>
          </td>
        </tr>
        </tbody></table>

        <!-- <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching Experience</heading>
                <ul>
                  <li> <b>Teaching Assistant (UGTA)</b> | UGTA for a course on Data Structures & Programming in C for Faculty Development Program at <a href="https://eict.iitr.ac.in/">Electronics and ICT Academy,
                    IIT Roorkee</a></li>
                </ul>
            </td>
          </tr>
        </table> -->
        
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td>
              <heading>Awards and Scholarships</heading>
                <ul>
                  <li> <b>Class Rank 2</b> | Ranked 2nd out of 76 students in <a href="https://iitr.ac.in/">IIT Roorkee</a> B.Tech. Computer Science batch of 2020.</li>
                  <!-- <li> <b>Rai Singh Jain & Mrs. Shakuntla Devi Jain Scholarship</b> | Awarded by <a href="https://iitr.ac.in/">IIT Roorkee</a> for the best academic performance among all B.Tech. CSE/ECE/Elec. programs up to 1st Year.</li>
                  <li> <b>1988 Batch Award</b> | Awarded by <a href="https://iitr.ac.in/">IIT Roorkee</a> for the best academic performance among all UG programs up to 1st semester.</li>
                  <li> <b>1988 Batch Award</b> | Awarded by <a href="https://iitr.ac.in/">IIT Roorkee</a>  for the best academic performance among all UG programs up to 1st year.</li> -->
                  <li> <b>KVPY Fellowship</b> | National <a href="http://www.kvpy.iisc.ernet.in/main/index.htm">Fellowship</a> awarded by <a href="https://iisc.ac.in/">Indian Institute of Science</a> and Govt. of INDIA.</li>
                </ul>
            </td>
          </tr>
        </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code from <a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron</a>
                	      
                <br>
                </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>